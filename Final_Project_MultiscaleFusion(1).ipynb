{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702037d-91a8-45d3-bfbb-f32ee373b7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c587a8ee-8a68-475c-a7ea-4ab4d337a5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian (240, 320, 3)\n",
      "gaussian (240, 320, 3)\n",
      "gaussian (240, 320, 3)\n",
      "gaussian (240, 320, 3)\n",
      "SHAPES:  (960, 1280, 3) (960, 1280, 3)\n",
      "SHAPES:  (480, 640, 3) (480, 640, 3)\n",
      "SHAPES:  (240, 320, 3) (240, 320, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 406\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 403\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    400\u001b[0m img \u001b[38;5;241m=\u001b[39m read_image(img_path)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# white_balanced = white_balanced_image(img.copy(), alpha = 2.3, compensate_blue_channel=True)\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# write_image(\"qqq.png\", white_balanced)\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m \u001b[43munderwater_image_enhancement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 334\u001b[0m, in \u001b[0;36munderwater_image_enhancement\u001b[0;34m(img, title)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# 图像重建\u001b[39;00m\n\u001b[1;32m    332\u001b[0m result \u001b[38;5;241m=\u001b[39m reconstruct_from_laplacian(result)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m--> 334\u001b[0m naive \u001b[38;5;241m=\u001b[39m (\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_weight_gamma_corrected\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimg_gamma_corrected\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mmultiply(combined_weight_sharpened,img_sharpen))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# #weights for gaussian pyramids\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# weight1 = pyramids[\"weight_0\"]\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# weight2 = pyramids[\"weight_1\"]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;66;03m# tmp.append(B)\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# result = cv2.merge(tmp,result)\u001b[39;00m\n\u001b[1;32m    391\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_result.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, result)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "#Load libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "def read_image(img_path):\n",
    "    return cv2.imread(img_path)\n",
    "\n",
    "def write_image(img_path, img):\n",
    "    cv2.imwrite(img_path, img)\n",
    "\n",
    "def normalize(pixel):\n",
    "    return np.float32(pixel) / 255\n",
    "\n",
    "def unnormalize(pixel):\n",
    "    return np.uint8(pixel * 255)\n",
    "\n",
    "def convert(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# def gray_world(img):\n",
    "#     dim = np.shape(img)[2]\n",
    "#     img = np.array(img, dtype='uint8')\n",
    "#     out = np.zeros(np.shape(img))\n",
    "#     avg = np.mean(np.mean(img))\n",
    "#     # 想较原始gray_world有改动\n",
    "#     for j in range(0, dim):\n",
    "#         m = np.sum(np.sum(img[:, :, j], axis=0), axis=0)\n",
    "#         n = np.size(img[:, :, j])\n",
    "#         scale = n/m\n",
    "#         g_weight = (avg*scale)\n",
    "#         out[:, :, j] = img[:, :, j]*g_weight\n",
    "#     out = np.array(out, dtype='uint8')\n",
    "#     return out\n",
    "    \n",
    "def gray_world(img):\n",
    "    # Convert image to float32 for precision during calculations\n",
    "    img_float = np.float32(img)\n",
    "\n",
    "    # Calculate the average of each channel\n",
    "    avg_b = np.mean(img_float[:, :, 0])  # Blue channel average\n",
    "    avg_g = np.mean(img_float[:, :, 1])  # Green channel average\n",
    "    avg_r = np.mean(img_float[:, :, 2])  # Red channel average\n",
    "\n",
    "    # Calculate the overall average (mean of the three channels)\n",
    "    avg_all = (avg_b + avg_g + avg_r) / 3.0\n",
    "\n",
    "    # Calculate scale factors for each channel\n",
    "    scale_b = avg_all / avg_b\n",
    "    scale_g = avg_all / avg_g\n",
    "    scale_r = avg_all / avg_r\n",
    "\n",
    "    # Apply the scaling factors to each channel\n",
    "    img_float[:, :, 0] *= scale_b  # Scale Blue channel\n",
    "    img_float[:, :, 1] *= scale_g  # Scale Green channel\n",
    "    img_float[:, :, 2] *= scale_r  # Scale Red channel\n",
    "\n",
    "    # Clip values to stay within valid range (0 to 255)\n",
    "    img_float = np.clip(img_float, 0, 255)\n",
    "\n",
    "    # Convert the image back to uint8\n",
    "    img_corrected = np.uint8(img_float)\n",
    "\n",
    "    return img_corrected\n",
    "\n",
    "# def white_balanced_image(img):\n",
    "#     img = np.double(img)\n",
    "#     R = img[:, :, 2]\n",
    "#     G = img[:, :, 1]\n",
    "#     B = img[:, :, 0]\n",
    "#     # 三颜色通道均值，对应 I¯r I¯g I¯b\n",
    "#     Irm = np.mean(R, axis=0)\n",
    "#     Irm = np.mean(Irm)/256.0\n",
    "#     Igm = np.mean(G, axis=0)\n",
    "#     Igm = np.mean(Igm)/256.0\n",
    "#     Ibm = np.mean(B, axis=0)\n",
    "#     Ibm = np.mean(Ibm)/256.0\n",
    "#     a = 1\n",
    "#     Irc = R + a * (Igm-Irm)*(1-Irm)*G  # 补偿红色通道\n",
    "#     Irc = np.array(Irc.reshape(G.shape), np.uint8)\n",
    "#     Ibc = B + a * (Igm-Ibm)*(1-Ibm)*G  # 补偿蓝色通道\n",
    "#     Ibc = np.array(Ibc.reshape(G.shape), np.uint8)\n",
    "\n",
    "#     G = np.array(G, np.uint8)\n",
    "#     img = cv2.merge([Ibc, G, Irc])\n",
    "#     return img\n",
    "    \n",
    "def white_balanced_image(img, alpha=1, compensate_blue_channel=False):\n",
    "    \"\"\"\n",
    "    Apply white balancing to red channel of BGR underwater images\n",
    "    \n",
    "    Args:\n",
    "        img (np.array): the image to apply white balancing to\n",
    "        alpha (int) (optional): The weight to apply to color correction (default = 1)\n",
    "        compensate_blue_channel (bool) (optional): Whether to also apply blue channel correction (need for cases of turbid waters, plankton) (default = False)\n",
    "    \"\"\"\n",
    "    if len(img.shape) < 3:\n",
    "        raise ValueError(\"Color image expected, received grayscale image\")\n",
    "    #img = img.copy()\n",
    "    mean_red = np.mean(img[:, :, 2])\n",
    "    mean_green = np.mean(img[:, :, 1])\n",
    "    mean_blue = np.mean(img[:, :, 0]) if compensate_blue_channel else None\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            img[i][j][2] = unnormalize(normalize(img[i][j][2]) + alpha * (normalize(mean_green) - normalize(mean_red)) * (1 - normalize(img[i][j][2])) * normalize(img[i][j][1]))\n",
    "            if compensate_blue_channel:\n",
    "                img[i][j][0] = unnormalize(normalize(img[i][j][0]) + alpha * (normalize(mean_green) - normalize(mean_blue)) * (1 - normalize(img[i][j][0])) * normalize(img[i][j][1]))\n",
    "    #cv2.imwrite(\"image_without_grayworld.jpg\", img)\n",
    "    #img = gray_world(img)#wb.balanceWhite(img)\n",
    "    return img\n",
    "\n",
    "def normalized_unsharp_masking(image):\n",
    "    # Convert the image to floating point format\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Apply Gaussian smoothing\n",
    "    im_blur = cv2.GaussianBlur(image,(7,7),0)\n",
    "\n",
    "    # Calculate unsharp mask\n",
    "    unsharp_mask = image - im_blur\n",
    "\n",
    "    # Perform histogram stretching\n",
    "    stretch_im = cv2.normalize(unsharp_mask, None, 0, 255, cv2.NORM_MINMAX) # type: ignore\n",
    "\n",
    "    # Combine original and stretched images\n",
    "    result = (image + stretch_im)/2\n",
    "\n",
    "    # Convert result back to uint8 format\n",
    "    result = np.clip(result, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return result\n",
    "        \n",
    "# def normalized_unsharp_masking(img, kernel_size=7):\n",
    "#     b, g, r = cv2.split(img)\n",
    "#     sharpened_channels = []\n",
    "#     for channel in [b, g, r]:\n",
    "#         blurred_channel = cv2.GaussianBlur(channel, (kernel_size, kernel_size), 0)\n",
    "#         sharpened_channel = channel - blurred_channel\n",
    "#         contrast_stretched_channel = cv2.normalize(sharpened_channel, None, 0, 255, cv2.NORM_MINMAX)\n",
    "#         sharpened_channels.append(contrast_stretched_channel)#cv2.addWeighted(channel, 1 + weight, sharpened_img, weight, 0))\n",
    "#     mask = cv2.merge(sharpened_channels)\n",
    "#     return np.uint8((img + mask) / 2)\n",
    "\n",
    "def gamma_correction(img, gamma_factor=1.2):\n",
    "    return np.uint8((img/255)**gamma_factor * 255)\n",
    "\n",
    "def laplacian_contrast_weight(img):\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.convertScaleAbs(cv2.Laplacian(img, cv2.CV_64F))\n",
    "\n",
    "def laplacian_contrast_weight(img):\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    w = cv2.Laplacian(img, cv2.CV_64F)\n",
    "    w = cv2.convertScaleAbs(w)\n",
    "    return w\n",
    "    \n",
    "# def saliency_weight(img):\n",
    "#     lab_image = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
    "    \n",
    "#     # Compute the mean pixel vector (I_mu)\n",
    "#     mean_pixel = lab_image.mean(axis=(0, 1), keepdims=True)  # Broadcast to full image size\n",
    "    \n",
    "#     # Apply Gaussian blur to the original image (I_ωhc)\n",
    "#     blurred_image = cv2.GaussianBlur(lab_image, (3, 3), 0)\n",
    "    \n",
    "#     # Compute the L2 norm (Euclidean distance) between I_mu and I_ωhc\n",
    "#     saliency_weight = np.linalg.norm(mean_pixel - blurred_image, axis=2)  # Across the Lab channels\n",
    "#     return saliency_weight\n",
    "\n",
    "def saliency_weight(img):\n",
    "    gfrgb = cv2.GaussianBlur(img,(3,3),0)\n",
    "    lab = cv2.cvtColor(gfrgb,cv2.COLOR_RGB2LAB)\n",
    "    l = np.double(lab[:, :, 0])\n",
    "    a = np.double(lab[:, :, 1])\n",
    "    b = np.double(lab[:, :, 2])\n",
    "    lm = np.mean(np.mean(l))\n",
    "    am = np.mean(np.mean(a))\n",
    "    bm = np.mean(np.mean(b))\n",
    "    w = np.square(l-lm) + np.square(a-am) + np.square((b-bm))\n",
    "    return w\n",
    "\n",
    "# def saturation_weight(grayscale_img, color_img):\n",
    "#     return np.linalg.norm(color_img - grayscale_img[..., np.newaxis], axis=2) / np.sqrt(3)\n",
    "#     # return np.sqrt((color_img[:,:,0] - grayscale_img)**2 + (color_img[:,:,1] - grayscale_img)**2 + (color_img[:,:,2] - grayscale_img)**2) / np.sqrt(3)\n",
    "\n",
    "def saturation_weight(img):\n",
    "    b,g,r=cv2.split(img)\n",
    "    lum=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    w=np.sqrt((1/3)*((r-lum)**2+(g-lum)**2+(b-lum)**2))\n",
    "    return w\n",
    "    \n",
    "def combine_weights(img1mask1, img1mask2, img1mask3, img2mask1, img2mask2, img2mask3):\n",
    "    img1_weight = img1mask1 + img1mask2 + img1mask3\n",
    "    img2_weight = img2mask1 + img2mask2 + img2mask3\n",
    "    img1_norm = (img1_weight + 0.1)/(img1_weight + img2_weight)\n",
    "    img2_norm = (img2_weight + 0.2)/(img1_weight + img2_weight)\n",
    "    img1_norm=np.repeat(img1_norm[:, :, np.newaxis], 3, axis=-1)\n",
    "    img2_norm=np.repeat(img2_norm[:, :, np.newaxis], 3, axis=-1)\n",
    "    return img1_norm, img2_norm\n",
    "\n",
    "def gaussian_pyramid(image, levels):\n",
    "    pyramid = [image]\n",
    "    for i in range(levels - 1):\n",
    "        image = cv2.pyrDown(image)\n",
    "        pyramid.append(image)\n",
    "    print(\"gaussian\", image.shape)\n",
    "    return pyramid\n",
    "\n",
    "def laplacian_pyramid(image, levels):\n",
    "    gaussian_pyramid_list = gaussian_pyramid(image, levels)\n",
    "    laplacian_pyramid = [gaussian_pyramid_list[-1]]\n",
    "\n",
    "    for i in range(levels - 1, 0, -1):\n",
    "        size = (gaussian_pyramid_list[i - 1].shape[1], gaussian_pyramid_list[i - 1].shape[0])\n",
    "        expanded = cv2.pyrUp(gaussian_pyramid_list[i], dstsize=size)\n",
    "        laplacian = cv2.subtract(gaussian_pyramid_list[i - 1], expanded)\n",
    "        laplacian_pyramid.insert(0, laplacian)\n",
    "    return laplacian_pyramid\n",
    "\n",
    "# 金字塔重建\n",
    "def reconstruct_from_laplacian(pyramid):\n",
    "    level = len(pyramid)\n",
    "\n",
    "    for i in range(level - 1, 0, -1):\n",
    "        m, n, c  = pyramid[i - 1].shape\n",
    "        pyramid[i - 1] += pyramid[i - 1] + cv2.resize(pyramid[i], (n, m))\n",
    "    output = pyramid[0]\n",
    "    output=np.clip(output, 0, 255).astype(np.uint8)\n",
    "    return output\n",
    "        \n",
    "\n",
    "# def gaussian_pyramid(image, levels):\n",
    "#     \"\"\"\n",
    "#     Generate a Gaussian pyramid from normalised_weight\n",
    "#     \"\"\"\n",
    "#     pyramid = [image]\n",
    "#     for _ in range(levels):\n",
    "#         image = cv2.pyrDown(image)\n",
    "#         pyramid.append(image)\n",
    "#     return pyramid\n",
    "\n",
    "# def laplacian_pyramid(image, levels):\n",
    "#     \"\"\"\n",
    "#     Generate a Laplacian pyramid for the given image.\n",
    "#     \"\"\"\n",
    "#     gaussian_pyr = gaussian_pyramid(image, levels)\n",
    "#     laplacian_pyr = []\n",
    "\n",
    "#     for i in range(levels):\n",
    "#         next_gaussian = cv2.pyrUp(gaussian_pyr[i + 1], dstsize=(gaussian_pyr[i].shape[1], gaussian_pyr[i].shape[0]))\n",
    "#         laplacian = cv2.subtract(gaussian_pyr[i], next_gaussian)\n",
    "#         laplacian_pyr.append(laplacian)\n",
    "\n",
    "#     laplacian_pyr.append(gaussian_pyr[-1])  # Add the smallest Gaussian at the top of the pyramid\n",
    "#     return laplacian_pyr\n",
    "\n",
    "# def reconstruct_from_laplacian(laplacian_pyr):\n",
    "#     \"\"\"\n",
    "#     Reconstruct the image from its Laplacian pyramid.\n",
    "#     \"\"\"\n",
    "#     reconstructed_image = laplacian_pyr[-1]\n",
    "\n",
    "#     for i in range(len(laplacian_pyr) - 2, -1, -1):\n",
    "#         reconstructed_image = cv2.pyrUp(reconstructed_image, dstsize=(laplacian_pyr[i].shape[1], laplacian_pyr[i].shape[0]))\n",
    "#         reconstructed_image = cv2.add(reconstructed_image, laplacian_pyr[i])\n",
    "\n",
    "#     return reconstructed_image\n",
    "    \n",
    "def underwater_image_enhancement(img, title):\n",
    "    img_normalized = normalize(img.copy())\n",
    "    img_balanced = white_balanced_image(img.copy(), compensate_blue_channel=True)\n",
    "    write_image(f\"{title}_white_balanced.jpg\", img_balanced)\n",
    "    \n",
    "    img_grayworld = gray_world(img_balanced.copy())\n",
    "    write_image(f\"{title}_grayworld.jpg\", img_grayworld)\n",
    "    \n",
    "    img_sharpened = normalized_unsharp_masking(img_grayworld.copy())\n",
    "    write_image(f\"{title}_sharpened.jpg\", img_sharpened)\n",
    "    \n",
    "    img_gamma_corrected = gamma_correction(img_grayworld, gamma_factor=2)\n",
    "    write_image(f\"{title}_gamma_corrected.jpg\", img_gamma_corrected)\n",
    "    \n",
    "    grayscale_gamma_corrected = cv2.cvtColor(img_gamma_corrected, cv2.COLOR_BGR2GRAY).astype(np.float64)/255\n",
    "    # write_image(f\"{title}_grayscale_gamma_corrected.jpg\", grayscale_gamma_corrected) \n",
    "    \n",
    "    grayscale_sharpened = cv2.cvtColor(img_sharpened, cv2.COLOR_BGR2GRAY).astype(np.float64)/255\n",
    "    # write_image(f\"{title}_grayscale_sharpened.jpg\", grayscale_sharpened)\n",
    "    \n",
    "    laplacian_contrast_weight_gamma_corrected = laplacian_contrast_weight(img_gamma_corrected)#grayscale_gamma_corrected)\n",
    "    # write_image(f\"{title}_laplacian_contrast_gamma_corrected.jpg\", laplacian_contrast_weight_gamma_corrected)\n",
    "    \n",
    "    laplacian_contrast_weight_sharpened = laplacian_contrast_weight(img_sharpened)#grayscale_sharpened) \n",
    "    # write_image(f\"{title}_laplacian_contrast_sharpened.jpg\", laplacian_contrast_weight_sharpened)\n",
    "\n",
    "    saliency_weight_gamma_corrected = saliency_weight(img_gamma_corrected)\n",
    "    write_image(f\"{title}_saliency_weight_gamma_corrected.jpg\", saliency_weight_gamma_corrected)  \n",
    "    \n",
    "    saliency_weight_sharpened = saliency_weight(img_sharpened)  \n",
    "    write_image(f\"{title}_saliency_weight_sharpened.jpg\", saliency_weight_sharpened) \n",
    "    \n",
    "    saturation_weight_gamma_corrected = saturation_weight(img_gamma_corrected)#grayscale_gamma_corrected, img_normalized)\n",
    "    write_image(f\"{title}_saturation_weight_gamma_corrected.jpg\", unnormalize(saturation_weight_gamma_corrected)) \n",
    "\n",
    "    saturation_weight_sharpened = saturation_weight(img_sharpened)#grayscale_sharpened, img_normalized)  \n",
    "    write_image(f\"{title}_saturation_weight_sharpened.jpg\", unnormalize(saturation_weight_sharpened)) \n",
    "\n",
    "    combined_weight_gamma_corrected, combined_weight_sharpened = combine_weights(laplacian_contrast_weight_gamma_corrected, saliency_weight_gamma_corrected, saturation_weight_gamma_corrected,\n",
    "                                                                                 laplacian_contrast_weight_sharpened, saliency_weight_sharpened, saturation_weight_sharpened)\n",
    "    write_image(f\"{title}_combined_weight_gamma_corrected.jpg\", unnormalize(combined_weight_gamma_corrected)) \n",
    "    write_image(f\"{title}_combined_weight_sharpened.jpg\", unnormalize(combined_weight_sharpened)) \n",
    "\n",
    "    # # Initialize a list or dictionary to store the pyramids for each normalized weight\n",
    "    # pyramids = {}\n",
    "    \n",
    "    # # Iterate over the normalized weights\n",
    "    # for i, weight in enumerate([combined_weight_gamma_corrected, combined_weight_sharpened]):\n",
    "    #     # Create a Gaussian pyramid for each normalized weight\n",
    "    #     pyramids[f\"weight_{i}\"] = gaussian_pyramid(weight, levels=5)\n",
    "    level = 3\n",
    "    input1_laplacian_pyramid=laplacian_pyramid(img_gamma_corrected,level)\n",
    "    input2_laplacian_pyramid=laplacian_pyramid(img_sharpened,level)\n",
    "\n",
    "    combined_weight_gamma_corrected = gaussian_pyramid(combined_weight_gamma_corrected, level)\n",
    "    combined_weight_sharpened = gaussian_pyramid(combined_weight_sharpened, level)\n",
    "    # 权值融合\n",
    "    result = []\n",
    "    for i in range(level):\n",
    "        print(\"SHAPES: \", combined_weight_gamma_corrected[i].shape, input1_laplacian_pyramid[i].shape)\n",
    "        fuse=np.multiply(combined_weight_gamma_corrected[i],input1_laplacian_pyramid[i])+ np.multiply(combined_weight_sharpened[i],input2_laplacian_pyramid[i])\n",
    "        result.append(fuse)\n",
    "    \n",
    "    # 图像重建\n",
    "    result = reconstruct_from_laplacian(result).astype(np.uint8)\n",
    "\n",
    "    naive = (np.multiply(combined_weight_gamma_corrected,img_gamma_corrected)+ np.multiply(combined_weight_sharpened,img_sharpen)).astype(np.uint8)\n",
    "    # #weights for gaussian pyramids\n",
    "    # weight1 = pyramids[\"weight_0\"]\n",
    "    # weight2 = pyramids[\"weight_1\"]\n",
    "\n",
    "    # #Cal Laplacian pyramid\n",
    "    # levels = 5\n",
    "    # blue_gamma, green_gamma, red_gamma = cv2.split(img_gamma_corrected)\n",
    "    # blue_sharpened, green_sharpened, red_sharpened = cv2.split(img_sharpened)\n",
    "\n",
    "    # blue_gamma_laplacian  = laplacian_pyramid(blue_gamma, levels)\n",
    "    # green_gamma_laplacian  = laplacian_pyramid(green_gamma, levels)\n",
    "    # red_gamma_laplacian  = laplacian_pyramid(red_gamma, levels)\n",
    "     \n",
    "    # blue_sharpened_laplacian  = laplacian_pyramid(blue_sharpened, levels)\n",
    "    # green_sharpened_laplacian  = laplacian_pyramid(green_sharpened, levels)\n",
    "    # red_sharpened_laplacian  = laplacian_pyramid(red_sharpened, levels)\n",
    "\n",
    "    # # Ensure that the lengths of the pyramids match\n",
    "    # num_levels = len(weight1)  # This should be the same for both weight1 and weight2\n",
    "    \n",
    "    # # Initialize the lists to store the result of the weighted pyramids\n",
    "    # R_r, G_r, B_r = [], [], []\n",
    "    \n",
    "    # # Iterate over the pyramid levels\n",
    "    # for i in range(num_levels):\n",
    "    #     R_r.append(np.array(weight1[i]) * red_gamma_laplacian[i] + np.array(weight2[i]) * red_sharpened_laplacian[i])\n",
    "    #     G_r.append(np.array(weight1[i]) * green_gamma_laplacian[i] + np.array(weight2[i]) * green_sharpened_laplacian[i])\n",
    "    #     B_r.append(np.array(weight1[i]) * blue_gamma_laplacian[i] + np.array(weight2[i]) * blue_sharpened_laplacian[i])\n",
    "    \n",
    "    # # Rebuild the pyramids from the weighted levels\n",
    "    # R = reconstruct_from_laplacian(R_r)\n",
    "    # G = reconstruct_from_laplacian(G_r)\n",
    "    # B = reconstruct_from_laplacian(B_r)\n",
    "\n",
    "    \n",
    "    # # Combine the channels back to a color image\n",
    "    # result = cv2.merge([B, G, R])\n",
    "\n",
    "    # R[R < 0] = 0\n",
    "    # R[R > 255] = 255\n",
    "    # R = R.astype(np.uint8)\n",
    "     \n",
    "    # G[G < 0] = 0\n",
    "    # G[G > 255] = 255\n",
    "    # G = G.astype(np.uint8)\n",
    "     \n",
    "    # B[B < 0] = 0\n",
    "    # B[B > 255] = 255\n",
    "    # B = B.astype(np.uint8)\n",
    "\n",
    "    # result = np.zeros(img.shape,dtype=img.dtype)\n",
    "    # tmp = []\n",
    "    # tmp.append(R)\n",
    "    # tmp.append(G)\n",
    "    # tmp.append(B)\n",
    "    # result = cv2.merge(tmp,result)\n",
    "    cv2.imwrite(f'{title}_result.jpg', result)\n",
    "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    cv2.imwrite(f'{title}_naive_result.jpg', naive)\n",
    "    plt.imshow(cv2.cvtColor(naive, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    img_path = 'initial_image.jpg'\n",
    "    img = read_image(img_path)\n",
    "    # white_balanced = white_balanced_image(img.copy(), alpha = 2.3, compensate_blue_channel=True)\n",
    "    # write_image(\"qqq.png\", white_balanced)\n",
    "    underwater_image_enhancement(img, img_path.split('.')[0])\n",
    "    print(\"Done\")\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed514823-131e-41e7-a17d-36b093a41c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the image\n",
    "# original_img_path = \"uwi.jpeg\"\n",
    "# sharp_img_path = \"uwi_sharpened.jpg\"  \n",
    "# gamma_img_path = \"uwi_gamma_corrected.jpg\"\n",
    "# original_img = cv2.imread(original_img_path, cv2.IMREAD_COLOR)\n",
    "# sharp_img = cv2.imread(sharp_img_path, cv2.IMREAD_COLOR)\n",
    "# gamma_img = cv2.imread(gamma_img_path, cv2.IMREAD_COLOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d863c33c-771a-4ca9-9634-ec574ffced1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Create a subplot for displaying both images\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(18, 6))  \n",
    "# # Display the original image\n",
    "# axs[0].imshow(original_img)\n",
    "# axs[0].set_title(\"Original Image\")\n",
    "# axs[0].axis(\"off\")\n",
    "# # Display the sharpened image\n",
    "# axs[1].imshow(sharp_img)\n",
    "# axs[1].set_title(\"Sharpened Image\")\n",
    "# axs[1].axis(\"off\")\n",
    "# # Display the gamma-corrected image\n",
    "# axs[2].imshow(gamma_img)\n",
    "# axs[2].set_title(\"Gamma-Corrected Image\")\n",
    "# axs[2].axis(\"off\")\n",
    "# # Show the plot\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700f94e-c573-4b08-aef4-669ddf8c7542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ed51a-18ca-452b-aee7-ecb5672bed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def compute_contrast_weight(image):\n",
    "#     \"\"\"\n",
    "#     Compute contrast weight map (W_S).\n",
    "#     \"\"\"\n",
    "#     W_s = cv2.Laplacian(image,cv2.CV_64F)\n",
    "\n",
    "#      # Normalize the absolute value to highlight edges\n",
    "#     contrast_weight = cv2.convertScaleAbs(W_s)\n",
    "\n",
    "#     contrast_weight = cv2.cvtColor(contrast_weight, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "#     return contrast_weight\n",
    "\n",
    "# def compute_saliency_weight(image):\n",
    "    \n",
    "    \n",
    "#     lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)\n",
    "    \n",
    "#     # Compute the mean pixel vector (I_mu)\n",
    "#     mean_pixel = lab_image.mean(axis=(0, 1), keepdims=True)  # Broadcast to full image size\n",
    "    \n",
    "#     # Apply Gaussian blur to the original image (I_ωhc)\n",
    "#     blurred_image = cv2.GaussianBlur(lab_image, (5, 5), 0)\n",
    "    \n",
    "#     # Compute the L2 norm (Euclidean distance) between I_mu and I_ωhc\n",
    "#     saliency_weight = np.linalg.norm(mean_pixel - blurred_image, axis=2)  # Across the Lab channels\n",
    "\n",
    "#     # Normalize saliency map for better visualization\n",
    "#     #saliency_weight = cv2.normalize(saliency_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "#     return saliency_weight\n",
    "\n",
    "\n",
    "# def compute_saturation_weight(image):\n",
    "#     \"\"\"\n",
    "#     Compute saturation weight map (W_Sat).\n",
    "#     \"\"\"\n",
    "#     # Normalize RGB channels to [0, 1]\n",
    "#     B, G, R = [image[..., i].astype(np.float32) / 255.0 for i in range(3)]\n",
    "    \n",
    "#     # Convert to grayscale (luminance)\n",
    "#     luminance = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0\n",
    "\n",
    "#     # Saturation weight map formula\n",
    "#     saturation_weight = np.sqrt((R - luminance)**2 + (G - luminance)**2 + (B - luminance)**2) / np.sqrt(3)\n",
    "#     return saturation_weight\n",
    "\n",
    "# def compute_aggregated_weight(image):\n",
    "#     \"\"\"\n",
    "#     Compute aggregated weight map W_k for a single input image.\n",
    "#     \"\"\"\n",
    "#     W_L = compute_saliency_weight(image)\n",
    "#     W_S = compute_contrast_weight(image)\n",
    "#     W_Sat = compute_saturation_weight(image)\n",
    "\n",
    "#     # Combine weights\n",
    "#     W_k = W_L + W_S + W_Sat\n",
    "#     return W_k, W_L, W_S, W_Sat\n",
    "\n",
    "# def normalize_weights(W_k_list, delta=0.1):\n",
    "#     \"\"\"\n",
    "#     Normalize weights across all images.\n",
    "#     \"\"\"\n",
    "#     # Sum of all weight maps + regularization term\n",
    "#     W_sum = sum(W_k_list) + delta * len(W_k_list)\n",
    "    \n",
    "#     # Normalize each W_k\n",
    "#     normalized_weights = [(W_k + delta) / W_sum for W_k in W_k_list]\n",
    "#     return normalized_weights\n",
    "\n",
    "# # Example usage\n",
    "# image_paths = [\"uwi_gamma_corrected.jpg\", \"uwi_sharpened.jpg\"] \n",
    "# W_k_list = []\n",
    "\n",
    "# # Compute weights for each image\n",
    "# for path in image_paths:\n",
    "#     # Load the image\n",
    "#     image = cv2.imread(path)\n",
    "#     if image is None:\n",
    "#         raise ValueError(f\"Image at {path} could not be loaded.\")\n",
    "\n",
    "#     # Compute weight maps\n",
    "#     W_k, W_L, W_S, W_Sat = compute_aggregated_weight(image)\n",
    "#     W_k_list.append(W_k)\n",
    "\n",
    "#     # Display the individual weight maps for each image\n",
    "#     plt.figure(figsize=(15, 5))\n",
    "#     titles = [\"Saliency Weight (W_L)\", \"Contrast Weight (W_S)\", \"Saturation Weight (W_Sat)\", \"Aggregated Weight (W_k)\"]\n",
    "#     weight_maps = [W_L, W_S, W_Sat, W_k]\n",
    "\n",
    "#     for i, (title, weight_map) in enumerate(zip(titles, weight_maps)):\n",
    "#         plt.subplot(1, 4, i + 1)\n",
    "#         plt.title(title)\n",
    "#         plt.imshow(weight_map, cmap = \"gray\")\n",
    "#         plt.axis('off')\n",
    "#     plt.suptitle(f\"Weight Maps for {path}\")\n",
    "#     plt.show()\n",
    "\n",
    "# # Normalize the weights across all images\n",
    "# normalized_weights = normalize_weights(W_k_list)\n",
    "\n",
    "# # Display normalized weights for the first image\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.title(\"Normalized Weight Map (Ŵ_k) for First Image\")\n",
    "# plt.imshow(normalized_weights[0], cmap = \"gray\")\n",
    "# plt.axis('off')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b924319c-42b0-4472-9b45-eed335e3abba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gaussian_pyramid(image, levels):\n",
    "#     \"\"\"\n",
    "#     Generate a Gaussian pyramid from normalised_weight\n",
    "#     \"\"\"\n",
    "#     pyramid = [image]\n",
    "#     for _ in range(levels):\n",
    "#         image = cv2.pyrDown(image)\n",
    "#         pyramid.append(image)\n",
    "#     return pyramid\n",
    "\n",
    "# # Initialize a list or dictionary to store the pyramids for each normalized weight\n",
    "# pyramids = {}\n",
    "\n",
    "# # Iterate over the normalized weights\n",
    "# for i, weight in enumerate(normalized_weights):\n",
    "#     # Create a Gaussian pyramid for each normalized weight\n",
    "#     pyramids[f\"weight_{i}\"] = gaussian_pyramid(weight, levels=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dffaa92-6095-47ad-aa3f-4d2aa8171991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #weights for gaussian pyramids\n",
    "# weight1 = pyramids[\"weight_0\"]\n",
    "# weight2 = pyramids[\"weight_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e2cd6-02b3-4f2b-bcdf-b4f6252d6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(weight1))\n",
    "# print(type(weight2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb515c9-81fe-4e0a-97f9-d2b4cdf98a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def laplacian_pyramid(image, levels):\n",
    "#     \"\"\"\n",
    "#     Generate a Laplacian pyramid for the given image.\n",
    "#     \"\"\"\n",
    "#     gaussian_pyr = gaussian_pyramid(image, levels)\n",
    "#     laplacian_pyr = []\n",
    "\n",
    "#     for i in range(levels):\n",
    "#         next_gaussian = cv2.pyrUp(gaussian_pyr[i + 1], dstsize=(gaussian_pyr[i].shape[1], gaussian_pyr[i].shape[0]))\n",
    "#         laplacian = cv2.subtract(gaussian_pyr[i], next_gaussian)\n",
    "#         laplacian_pyr.append(laplacian)\n",
    "\n",
    "#     laplacian_pyr.append(gaussian_pyr[-1])  # Add the smallest Gaussian at the top of the pyramid\n",
    "#     return laplacian_pyr\n",
    "\n",
    "# def reconstruct_from_laplacian(laplacian_pyr):\n",
    "#     \"\"\"\n",
    "#     Reconstruct the image from its Laplacian pyramid.\n",
    "#     \"\"\"\n",
    "#     reconstructed_image = laplacian_pyr[-1]\n",
    "\n",
    "#     for i in range(len(laplacian_pyr) - 2, -1, -1):\n",
    "#         reconstructed_image = cv2.pyrUp(reconstructed_image, dstsize=(laplacian_pyr[i].shape[1], laplacian_pyr[i].shape[0]))\n",
    "#         reconstructed_image = cv2.add(reconstructed_image, laplacian_pyr[i])\n",
    "\n",
    "#     return reconstructed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e081fdb-1002-45c2-b2b7-3aff17ff0f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_rgb(image):\n",
    "#     red = None\n",
    "#     green = None\n",
    "#     blue = None\n",
    "#     (blue, green, red) = cv2.split(image)\n",
    "#     return red, green, blue\n",
    "    \n",
    "# (R1,G1,B1)= split_rgb(gamma_img)\n",
    "# (R2,G2,B2)= split_rgb(sharp_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654adf20-506e-4365-a8d3-1ddecc2e6cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Cal Laplacian pyramid\n",
    "# levels = 5\n",
    "# r1  = laplacian_pyramid(R1, levels)\n",
    "# g1  = laplacian_pyramid(G1, levels)\n",
    "# b1  = laplacian_pyramid(B1, levels)\n",
    " \n",
    "# r2 = laplacian_pyramid(R2, levels)\n",
    "# g2 = laplacian_pyramid(G2, levels)\n",
    "# b2 = laplacian_pyramid(B2, levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc1e71-cbe4-4d9d-8156-d744c72ff070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensure that the lengths of the pyramids match\n",
    "# num_levels = len(weight1)  # This should be the same for both weight1 and weight2\n",
    "\n",
    "# # Initialize the lists to store the result of the weighted pyramids\n",
    "# R_r, G_r, B_r = [], [], []\n",
    "\n",
    "# # Iterate over the pyramid levels\n",
    "# for i in range(num_levels):\n",
    "#     R_r.append(np.array(weight1[i]) * r1[i] + np.array(weight2[i]) * r2[i])\n",
    "#     G_r.append(np.array(weight1[i]) * g1[i] + np.array(weight2[i]) * g2[i])\n",
    "#     B_r.append(np.array(weight1[i]) * b1[i] + np.array(weight2[i]) * b2[i])\n",
    "\n",
    "# # Rebuild the pyramids from the weighted levels\n",
    "# R = reconstruct_from_laplacian(R_r)\n",
    "# G = reconstruct_from_laplacian(G_r)\n",
    "# B = reconstruct_from_laplacian(B_r)\n",
    "\n",
    "# # Combine the channels back to a color image\n",
    "# result = cv2.merge([B, G, R])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f884774-7455-4ffa-aab4-167300604980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R[R < 0] = 0\n",
    "# R[R > 255] = 255\n",
    "# R = R.astype(np.uint8)\n",
    " \n",
    "# G[G < 0] = 0\n",
    "# G[G > 255] = 255\n",
    "# G = G.astype(np.uint8)\n",
    " \n",
    "# B[B < 0] = 0\n",
    "# B[B > 255] = 255\n",
    "# B = B.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c39397-b54e-4a43-9f06-993772180b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = np.zeros(gamma_img.shape,dtype=gamma_img.dtype)\n",
    "# tmp = []\n",
    "# tmp.append(R)\n",
    "# tmp.append(G)\n",
    "# tmp.append(B)\n",
    "# result = cv2.merge(tmp,result)\n",
    "\n",
    "# # Display the images\n",
    "# plt.imshow(result)\n",
    "# plt.title(\"Result Image\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(gamma_img)\n",
    "# plt.title(\"Gamma Image\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(sharp_img)\n",
    "# plt.title(\"Sharp Image\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e04567-157e-404c-9732-1a695026bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the result image\n",
    "# cv2.imwrite(\"result11.jpg\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03929749-0726-4e09-bbd3-a1051bdced35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c89a142-d937-4e33-9186-25e9c2dc7fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d879e-164e-4fa7-84d1-5a07755cde12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1abe6c-81a7-4403-93a8-471c99c1d68d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
